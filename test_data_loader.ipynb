{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582eb461",
   "metadata": {},
   "source": [
    "## üìä Examine Downloaded WRDS Data\n",
    "\n",
    "Let's check the quality and structure of the downloaded CRSP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98475b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç EXAMINING DOWNLOADED CRSP DATA\n",
      "==================================================\n",
      "üìÅ Looking for data file: data\\stock_data_raw.csv\n",
      "‚úÖ Data file found! Loading...\n",
      "\n",
      "üìä DATASET OVERVIEW:\n",
      "   Total observations: 938,008\n",
      "   Unique stocks (PERMNO): 10,848\n",
      "   Date range: 1965-01-29 to 1989-12-29\n",
      "   Columns: ['date', 'permno', 'ticker', 'ret', 'prc', 'shrout', 'exchcd', 'shrcd', 'vol', 'market_cap']\n",
      "\n",
      "üèóÔ∏è DATA STRUCTURE:\n",
      "   Data shape: (938008, 10)\n",
      "   Memory usage: 118.2 MB\n",
      "\n",
      "üìã FIRST 5 ROWS:\n",
      "        date  permno ticker       ret     prc  shrout  exchcd  shrcd     vol  \\\n",
      "0 1986-02-28   10001   GFGC  0.020408  6.2500   985.0       3     11  1067.0   \n",
      "1 1986-03-31   10001   GFGC  0.025200  6.3125   985.0       3     11   335.0   \n",
      "2 1986-04-30   10001   GFGC  0.009901  6.3750   985.0       3     11   225.0   \n",
      "3 1986-05-30   10001   GFGC -0.009804  6.3125   985.0       3     11   217.0   \n",
      "4 1986-06-30   10001   GFGC -0.013069  6.1250   985.0       3     11   238.0   \n",
      "\n",
      "   market_cap  \n",
      "0    6.156250  \n",
      "1    6.217812  \n",
      "2    6.279375  \n",
      "3    6.217812  \n",
      "4    6.033125  \n"
     ]
    }
   ],
   "source": [
    "# Load and examine the downloaded CRSP data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import config\n",
    "\n",
    "print(\"üîç EXAMINING DOWNLOADED CRSP DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if data file exists\n",
    "data_file = Path(config.DATA_DIR) / \"stock_data_raw.csv\"\n",
    "print(f\"üìÅ Looking for data file: {data_file}\")\n",
    "\n",
    "if data_file.exists():\n",
    "    print(\"‚úÖ Data file found! Loading...\")\n",
    "    \n",
    "    # Load the data\n",
    "    downloaded_data = pd.read_csv(data_file)\n",
    "    downloaded_data['date'] = pd.to_datetime(downloaded_data['date'])\n",
    "    \n",
    "    print(f\"\\nüìä DATASET OVERVIEW:\")\n",
    "    print(f\"   Total observations: {len(downloaded_data):,}\")\n",
    "    print(f\"   Unique stocks (PERMNO): {downloaded_data['permno'].nunique():,}\")\n",
    "    print(f\"   Date range: {downloaded_data['date'].min().date()} to {downloaded_data['date'].max().date()}\")\n",
    "    print(f\"   Columns: {list(downloaded_data.columns)}\")\n",
    "    \n",
    "    # Check data structure\n",
    "    print(f\"\\nüèóÔ∏è DATA STRUCTURE:\")\n",
    "    print(f\"   Data shape: {downloaded_data.shape}\")\n",
    "    print(f\"   Memory usage: {downloaded_data.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nüìã FIRST 5 ROWS:\")\n",
    "    print(downloaded_data.head())\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Data file not found!\")\n",
    "    print(\"üí° Run the download script first: python download_wrds_data.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b301f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ DATA QUALITY ANALYSIS\n",
      "========================================\n",
      "\n",
      "üìâ Missing Values:\n",
      "   ticker: 6,012 (0.64%)\n",
      "   vol: 175,577 (18.72%)\n",
      "\n",
      "üìä Data Statistics:\n",
      "   Returns - Mean: 0.0187, Std: 0.1274\n",
      "   Returns - Min: -0.8102, Max: 5.5625\n",
      "   Prices - Min: $5.00, Max: $8675.00\n",
      "   Market Cap - Min: $0.00M, Max: $102022.29M\n",
      "\n",
      "üè¢ Exchange Distribution:\n",
      "   NYSE (1): 386,700 (41.2%)\n",
      "   AMEX (2): 187,485 (20.0%)\n",
      "   NASDAQ (3): 363,823 (38.8%)\n",
      "\n",
      "üìÖ Time Coverage:\n",
      "   Total months: 300\n",
      "   Avg observations per month: 3127\n",
      "   Min observations per month: 1791\n",
      "   Max observations per month: 4494\n",
      "\n",
      "üéâ DATA QUALITY SUMMARY:\n",
      "   ‚úÖ 938,008 total observations\n",
      "   ‚úÖ Complete 1965-1989 period\n",
      "   ‚úÖ 10,848 unique stocks\n",
      "   ‚úÖ All required columns present\n",
      "   ‚úÖ Data ready for momentum analysis!\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Analysis\n",
    "print(\"üî¨ DATA QUALITY ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüìâ Missing Values:\")\n",
    "missing_counts = downloaded_data.isnull().sum()\n",
    "for col, count in missing_counts.items():\n",
    "    if count > 0:\n",
    "        pct = (count / len(downloaded_data)) * 100\n",
    "        print(f\"   {col}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "if missing_counts.sum() == 0:\n",
    "    print(\"   ‚úÖ No missing values found!\")\n",
    "\n",
    "# Check data types and ranges\n",
    "print(f\"\\nüìä Data Statistics:\")\n",
    "print(f\"   Returns - Mean: {downloaded_data['ret'].mean():.4f}, Std: {downloaded_data['ret'].std():.4f}\")\n",
    "print(f\"   Returns - Min: {downloaded_data['ret'].min():.4f}, Max: {downloaded_data['ret'].max():.4f}\")\n",
    "print(f\"   Prices - Min: ${downloaded_data['prc'].min():.2f}, Max: ${downloaded_data['prc'].max():.2f}\")\n",
    "print(f\"   Market Cap - Min: ${downloaded_data['market_cap'].min():.2f}M, Max: ${downloaded_data['market_cap'].max():.2f}M\")\n",
    "\n",
    "# Check exchange distribution\n",
    "print(f\"\\nüè¢ Exchange Distribution:\")\n",
    "exchange_dist = downloaded_data['exchcd'].value_counts().sort_index()\n",
    "for exchcd, count in exchange_dist.items():\n",
    "    pct = (count / len(downloaded_data)) * 100\n",
    "    exchange_name = {1: 'NYSE', 2: 'AMEX', 3: 'NASDAQ'}.get(exchcd, f'Exchange {exchcd}')\n",
    "    print(f\"   {exchange_name} ({exchcd}): {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Check time coverage\n",
    "print(f\"\\nüìÖ Time Coverage:\")\n",
    "monthly_obs = downloaded_data.groupby(downloaded_data['date'].dt.to_period('M')).size()\n",
    "print(f\"   Total months: {len(monthly_obs)}\")\n",
    "print(f\"   Avg observations per month: {monthly_obs.mean():.0f}\")\n",
    "print(f\"   Min observations per month: {monthly_obs.min()}\")\n",
    "print(f\"   Max observations per month: {monthly_obs.max()}\")\n",
    "\n",
    "print(f\"\\nüéâ DATA QUALITY SUMMARY:\")\n",
    "print(f\"   ‚úÖ {len(downloaded_data):,} total observations\")\n",
    "print(f\"   ‚úÖ Complete {downloaded_data['date'].min().year}-{downloaded_data['date'].max().year} period\")\n",
    "print(f\"   ‚úÖ {downloaded_data['permno'].nunique():,} unique stocks\")\n",
    "print(f\"   ‚úÖ All required columns present\")\n",
    "print(f\"   ‚úÖ Data ready for momentum analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jt1993-momentum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
